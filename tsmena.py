# -*- coding: utf-8 -*-
"""tsmena

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YdEjcT5VOawUifYXMimqrqUVVncouYCm
"""

import re
from collections import defaultdict, deque

def normalize_word(word):
    return re.sub(r"[^a-z']", "", word.lower())

def words_are_similar(word1, word2):
    if len(word1) == 1 or len(word2) == 1:
        return False

    if len(word1) == len(word2):
        mismatches = 0
        for i in range(len(word1)):
            if word1[i] != word2[i]:
                mismatches += 1
        return mismatches == 1

    if abs(len(word1) - len(word2)) == 1:
        if len(word1) > len(word2):
            long_word, short_word = word1, word2
        else:
            long_word, short_word = word2, word1

        if long_word[:-1] == short_word and long_word[-1] in ('e', 's'):
            return True

    return False

def find_all_word_groups(word_list):
    unique_words = set(word_list)
    visited_words = set()
    all_groups = []

    for word in unique_words:
        if word in visited_words:
            continue

        current_group = set()
        queue = deque([word])

        while queue:
            current_word = queue.popleft()
            if current_word in visited_words:
                continue

            visited_words.add(current_word)
            current_group.add(current_word)

            for candidate in unique_words:
                if candidate not in visited_words and words_are_similar(current_word, candidate):
                    queue.append(candidate)

        all_groups.append(current_group)

    return all_groups

def count_context_occurrences(words_sequence, groups, context_radius):
    word_to_group_map = {}
    for group in groups:
        for word in group:
            word_to_group_map[word] = group

    frequency_counter = defaultdict(int)

    for position, current_word in enumerate(words_sequence):
        if current_word not in word_to_group_map:
            continue

        current_group = word_to_group_map[current_word]
        has_similar_neighbor = False

        start_pos = max(0, position - context_radius)
        end_pos = min(len(words_sequence), position + context_radius + 1)

        for neighbor_pos in range(start_pos, end_pos):
            if neighbor_pos == position:
                continue

            neighbor_word = words_sequence[neighbor_pos]
            if (neighbor_word in word_to_group_map and
                word_to_group_map[neighbor_word] == current_group):
                has_similar_neighbor = True
                break

        if has_similar_neighbor:
            frequency_counter[frozenset(current_group)] += 1

    return frequency_counter

def main():
    import sys
    input_data = sys.stdin.read().strip().splitlines()

    if not input_data:
        return

    try:
        k_value = int(input_data[0])
    except ValueError:
        print("Ошибка: первая строка должна содержать целое число K")
        return

    text_lines = [line.strip() for line in input_data[1:] if line.strip()]
    if not text_lines:
        return

    full_text = " ".join(text_lines)
    raw_words = re.findall(r"\S+", full_text)
    normalized_words = [normalize_word(w) for w in raw_words]
    valid_words = [w for w in normalized_words if w]

    word_groups = find_all_word_groups(valid_words)
    frequencies = count_context_occurrences(valid_words, word_groups, k_value)

    output_results = []
    for group, freq in frequencies.items():
        if freq > 0:
            representative_word = min(group)
            output_results.append((representative_word, freq))

    output_results.sort(key=lambda item: (-item[1], item[0]))

    for word, count in output_results:
        print(f"{word}: {count}")

if __name__ == "__main__":
    main()